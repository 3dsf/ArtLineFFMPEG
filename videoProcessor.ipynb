{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "videoProcessor.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HRjmZ9FD4mAg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3dsf/ArtLineFFMPEG/blob/main/videoProcessor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8AgUL1FgGEq"
      },
      "source": [
        "# Video Processing with AI models\n",
        "based on the ffmpeg-python tensorflow implementation \n",
        "and using the models of \n",
        "https://github.com/vijishmadhavan\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRjmZ9FD4mAg"
      },
      "source": [
        "# Install Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8YPFvvMVVvx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ba527a-5801-4bd3-a73a-6ecda249d910"
      },
      "source": [
        "!pip install youtube-dl fastai==1.0.61 ffmpeg-python"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting youtube-dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/93/3faf0e257fe2d37672901b46739bf63e198066e53dd02d956d6b2daa9c49/youtube_dl-2021.4.26-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 18.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: fastai==1.0.61 in /usr/local/lib/python3.7/dist-packages (1.0.61)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (2.7.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (3.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (1.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (0.9.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (2.23.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (1.0.0)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (7.352.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (7.1.2)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (1.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (1.1.5)\n",
            "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (2.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (4.6.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.61) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.61) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.61) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.61) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.61) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.61) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.61) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.61) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==1.0.61) (2018.9)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (56.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (0.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->fastai==1.0.61) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fastai==1.0.61) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (3.4.1)\n",
            "Installing collected packages: youtube-dl, ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0 youtube-dl-2021.4.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt5OjMJxEcmz"
      },
      "source": [
        "# Select\n",
        "## -- Model\n",
        "## -- Video\n",
        "## -- Output Name\n",
        "*and collect metadata*\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOGWZjslqwGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "ae92424e-2c32-4c40-9743-5b9d03236ad7"
      },
      "source": [
        "import os\n",
        "\n",
        "modelToRun = \"ArtLine_1024.pkl\" #@param [\"ArtLine_500.pkl\", \"ArtLine_650.pkl\", \"ArtLine_1024.pkl\", \"SkinDeep.pkl\", \"SkinDeep_1280.pkl\"]\n",
        "pathToModel = os.path.join(\"/content/drive/\",modelToRun)\n",
        "\n",
        "downloadModel = {\n",
        "    \"ArtLine_500.pkl\": \"https://www.dropbox.com/s/p9lynpwygjmeed2/ArtLine_500.pkl\",\n",
        "    \"ArtLine_650.pkl\": \"https://www.dropbox.com/s/starqc9qd2e1lg1/ArtLine_650.pkl\",\n",
        "    \"ArtLine_1024.pkl\": \"https://www.dropbox.com/s/rq90q9lr9arwdp8/ArtLine_1024%20%281%29.pkl\",\n",
        "    \"SkinDeep.pkl\": \"https://www.dropbox.com/s/5mmcqao4mozpube/SkinDeep.pkl?dl=1\",\n",
        "    \"SkinDeep_1280.pkl\": \"https://www.dropbox.com/s/wxty56nhidusojr/SkinDeep_1280.pkl\"\n",
        "}\n",
        "if os.path.isfile(pathToModel) == False : \n",
        "    if os.path.isfile(modelToRun) == False :\n",
        "        print(\"Downloading Model\")\n",
        "        download = downloadModel[modelToRun]\n",
        "        !wget -O $modelToRun $download\n",
        "        pathToModel = modelToRun\n",
        "    else :\n",
        "        print(\"Found Local Version\")\n",
        "        pathToModel = modelToRun\n",
        "\n",
        "videoURL = \"https://www.youtube.com/watch?v=FcU-LQ5VmhE\" #@param {type:\"string\"}\n",
        "!rm input.mp4  #required\n",
        "!time(youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=acc]/mp4' --output \"input.%(ext)s\"  $videoURL)\n",
        "output_name = \"ocieElliot.likeAriver.artLine_1024.mp4\" #@param {type:\"string\"}\n",
        "\n",
        "import subprocess\n",
        "AUDIO = False\n",
        "process = subprocess.Popen(['ffmpeg', '-hide_banner', '-i', 'input.mp4', '-y' ], stdout=subprocess.PIPE, stderr=subprocess.STDOUT,universal_newlines=True)\n",
        "for line in process.stdout:\n",
        "    print(line)\n",
        "    if ' Video:' in line:\n",
        "        l_split = line.split(',')\n",
        "        #print('---------printing line \", line)\n",
        "        for segment in l_split[1:]:\n",
        "            if 'fps' in segment:\n",
        "                    s = segment.strip().split(' ')\n",
        "                    fps = float(s[0])\n",
        "            if 'x' in segment:\n",
        "                    s = segment.strip().split('x')\n",
        "                    width = int(s[0])\n",
        "                    s2 = s[1].split(' ')\n",
        "                    height = int(s2[0])\n",
        "    if 'Duration:' in line:\n",
        "        s = line.split(',')\n",
        "        ss = s[0].split(' ')\n",
        "        sss = ss[3].strip().split(':')\n",
        "        seconds = float(sss[0])*60*60 + float(sss[1])*60 + float(sss[2])\n",
        "    if 'Audio:' in line:\n",
        "        AUDIO = True\n",
        "\n",
        "print('fps = ', str(fps))\n",
        "print('width = ', str(width))\n",
        "print('height = ', str(height))\n",
        "print('seconds = ', str(seconds))\n",
        "print('AUDIO = ', AUDIO)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Model\n",
            "--2021-05-03 04:33:20--  https://www.dropbox.com/s/rq90q9lr9arwdp8/ArtLine_1024%20%281%29.pkl\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/rq90q9lr9arwdp8/ArtLine_1024%20%281%29.pkl [following]\n",
            "--2021-05-03 04:33:20--  https://www.dropbox.com/s/raw/rq90q9lr9arwdp8/ArtLine_1024%20%281%29.pkl\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc88f973dd4ef73337666c71c23f.dl.dropboxusercontent.com/cd/0/inline/BNyot52fVfxVjs1I2lWSeXnsdk1xxqcG0UKj0e7gdc5U3IB5AoMXelOiWFZQvzPsFjCCT6D9VnClsyqx7XwWYU2V8HjZA4iOGsP3kkzwgVI9bkT9Z5mS3nXcyPbkYz6u0O_nFDPO-_s7AsHdxyxYpciM/file# [following]\n",
            "--2021-05-03 04:33:21--  https://uc88f973dd4ef73337666c71c23f.dl.dropboxusercontent.com/cd/0/inline/BNyot52fVfxVjs1I2lWSeXnsdk1xxqcG0UKj0e7gdc5U3IB5AoMXelOiWFZQvzPsFjCCT6D9VnClsyqx7XwWYU2V8HjZA4iOGsP3kkzwgVI9bkT9Z5mS3nXcyPbkYz6u0O_nFDPO-_s7AsHdxyxYpciM/file\n",
            "Resolving uc88f973dd4ef73337666c71c23f.dl.dropboxusercontent.com (uc88f973dd4ef73337666c71c23f.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to uc88f973dd4ef73337666c71c23f.dl.dropboxusercontent.com (uc88f973dd4ef73337666c71c23f.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BNyX9Rze3NiNAbl6uoN2DKdH1TOWse-1W6YOdGe0kR1yj5hr5DLX2Q5QfxJIVMfWXC4XpxBPYPnbh-W1Tr7lx6vfYUn1jLr5PTP-eTqNSjgJc20e2raQz4TmJtb7rBzLYiwVPpyFvPzboyC0zNqjzrq95ZTjJGWcELPDx96YUbGooGA2w92WH36rQb_SMrfmNs0PjkFcL0-dpay5Hg5BMurU556Bj4PK5ttVISQC7y95-ZwBP76pFoR6KiVvCDxiV5y4CW2itpWrRU8meNYmOHZFBgpdkmY4ZLcNCmLMU8MgoAYSSGW-dkMt911IpPxuyPYb7ZLAWA62bIgjG3Mtt652ZOaBLeIdSnJZo9c5qOPv8SS4rI-YfopihzFS_0Yv-FA/file [following]\n",
            "--2021-05-03 04:33:21--  https://uc88f973dd4ef73337666c71c23f.dl.dropboxusercontent.com/cd/0/inline2/BNyX9Rze3NiNAbl6uoN2DKdH1TOWse-1W6YOdGe0kR1yj5hr5DLX2Q5QfxJIVMfWXC4XpxBPYPnbh-W1Tr7lx6vfYUn1jLr5PTP-eTqNSjgJc20e2raQz4TmJtb7rBzLYiwVPpyFvPzboyC0zNqjzrq95ZTjJGWcELPDx96YUbGooGA2w92WH36rQb_SMrfmNs0PjkFcL0-dpay5Hg5BMurU556Bj4PK5ttVISQC7y95-ZwBP76pFoR6KiVvCDxiV5y4CW2itpWrRU8meNYmOHZFBgpdkmY4ZLcNCmLMU8MgoAYSSGW-dkMt911IpPxuyPYb7ZLAWA62bIgjG3Mtt652ZOaBLeIdSnJZo9c5qOPv8SS4rI-YfopihzFS_0Yv-FA/file\n",
            "Reusing existing connection to uc88f973dd4ef73337666c71c23f.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 394289028 (376M) [application/octet-stream]\n",
            "Saving to: ‘ArtLine_1024.pkl’\n",
            "\n",
            "ArtLine_1024.pkl    100%[===================>] 376.02M   200MB/s    in 1.9s    \n",
            "\n",
            "2021-05-03 04:33:24 (200 MB/s) - ‘ArtLine_1024.pkl’ saved [394289028/394289028]\n",
            "\n",
            "rm: cannot remove 'input.mp4': No such file or directory\n",
            "[youtube] FcU-LQ5VmhE: Downloading webpage\n",
            "[youtube] FcU-LQ5VmhE: Downloading player bce81a70\n",
            "[download] Destination: input.mp4\n",
            "\u001b[K[download] 100% of 8.11MiB in 00:00\n",
            "\n",
            "real\t0m1.706s\n",
            "user\t0m1.032s\n",
            "sys\t0m0.074s\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input.mp4':\n",
            "\n",
            "  Metadata:\n",
            "\n",
            "    major_brand     : mp42\n",
            "\n",
            "    minor_version   : 0\n",
            "\n",
            "    compatible_brands: isommp42\n",
            "\n",
            "    creation_time   : 2021-04-28T15:08:46.000000Z\n",
            "\n",
            "  Duration: 00:03:26.50, start: 0.000000, bitrate: 329 kb/s\n",
            "\n",
            "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 230 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
            "\n",
            "    Metadata:\n",
            "\n",
            "      creation_time   : 2021-04-28T15:08:46.000000Z\n",
            "\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 04/28/2021.\n",
            "\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\n",
            "\n",
            "    Metadata:\n",
            "\n",
            "      creation_time   : 2021-04-28T15:08:46.000000Z\n",
            "\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 04/28/2021.\n",
            "\n",
            "At least one output file must be specified\n",
            "\n",
            "fps =  29.97\n",
            "width =  640\n",
            "height =  360\n",
            "seconds =  206.5\n",
            "AUDIO =  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWywo0Pageln"
      },
      "source": [
        "# Process Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcuaaaJYW3ip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "12dc9b17-1440-415a-9dae-e4b3aea34405"
      },
      "source": [
        "import os\n",
        "import logging as logger\n",
        "\n",
        "from torchvision import transforms as T\n",
        "from fastai.utils.mem import *\n",
        "from fastai.vision import open_image, load_learner, Image, torch, pil2tensor, image2np\n",
        "\n",
        "import ffmpeg, cv2\n",
        "import numpy as np\n",
        "\n",
        "#progress bar\n",
        "from IPython.display import HTML, display\n",
        "from tqdm import *\n",
        "\n",
        "#There is scaling warning that might come up, and this block supresses user warnings\n",
        "#Comment out this block if your don't mind seeing the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)  \n",
        "\n",
        "### Progress bar\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "### Class required for model\n",
        "class FeatureLoss(nn.Module):\n",
        "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
        "        super().__init__()\n",
        "        self.m_feat = m_feat\n",
        "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
        "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
        "        self.wgts = layer_wgts\n",
        "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
        "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
        "\n",
        "    def make_features(self, x, clone=False):\n",
        "        self.m_feat(x)\n",
        "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        out_feat = self.make_features(target, clone=True)\n",
        "        in_feat = self.make_features(input)\n",
        "        self.feat_losses = [base_loss(input,target)]\n",
        "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
        "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
        "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
        "        return sum(self.feat_losses)\n",
        "\n",
        "    def __del__(self): self.hooks.remove()\n",
        "\n",
        "### DETERMINE IF CUDA AVAILABLE and LOAD MODEL\n",
        "def modelDeviceLoadSelect():  \n",
        "    if torch.cuda.is_available():\n",
        "        def load_model():\n",
        "            global USEgPU\n",
        "            learn = load_learner('.', pathToModel, device=0 )\n",
        "            USEgPU = True\n",
        "            print(\"INFERENCE DEVICE : cuda\")\n",
        "            return learn\n",
        "    else:\n",
        "        def load_model():\n",
        "            learn = load_learner('.', pathToModel, device='cpu')\n",
        "            print(\"INFERENCE DEVICE : cpu\")\n",
        "            return learn\n",
        "    learn=load_model()\n",
        "    return learn\n",
        "\n",
        "### Functions based on ffmpeg-python video tensorflow example\n",
        "def readFrameAsNp(ffmpegDecode, width, height):\n",
        "    logger.debug('Reading frame')\n",
        "\n",
        "    # Note: RGB24 == 3 bytes per pixel.\n",
        "    frame_size = width * height * 3\n",
        "    in_bytes = ffmpegDecode.stdout.read(frame_size)\n",
        "    if len(in_bytes) == 0:\n",
        "        frame = None\n",
        "    else:\n",
        "        assert len(in_bytes) == frame_size\n",
        "        frame = (\n",
        "            np\n",
        "            .frombuffer(in_bytes, np.uint8)\n",
        "            .reshape([height, width, 3])\n",
        "        )\n",
        "    return frame\n",
        "\n",
        "def writeFrameAsByte(ffmpegEncode, frame):\n",
        "    logger.debug('Writing frame')\n",
        "    ffmpegEncode.stdin.write(\n",
        "        frame\n",
        "        .astype(np.uint8)\n",
        "        .tobytes()\n",
        "    )\n",
        "\n",
        "def vid2np(in_filename):\n",
        "    logger.info('vid2np() -- Decoding to pipe')\n",
        "    codec = 'h264'\n",
        "    args = (\n",
        "            ffmpeg\n",
        "            .input(in_filename,\n",
        "                **{'c:v': codec})\n",
        "            .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
        "            .global_args(\"-hide_banner\")\n",
        "            .compile()\n",
        "    )\n",
        "    return subprocess.Popen(args, stdout=subprocess.PIPE)\n",
        "\n",
        "def np2vid(out_filename, fps_out, in_file, widthOut, heightOut):\n",
        "    logger.info('np2vid() encoding from pipe')\n",
        "    global AUDIO\n",
        "    codec = 'h264'\n",
        "    if AUDIO == True :\n",
        "        pipeline2 = ffmpeg.input(in_file)\n",
        "        audio = pipeline2.audio\n",
        "        args = (\n",
        "            ffmpeg\n",
        "            .input('pipe:', format='rawvideo', pix_fmt='rgb24',\n",
        "                s='{}x{}'.format(widthOut, heightOut),\n",
        "                framerate=fps_out )\n",
        "            .output(audio, out_filename , pix_fmt='yuv420p', **{'c:v': codec}, \n",
        "                shortest=None, acodec='copy')\n",
        "            .global_args(\"-hide_banner\")\n",
        "            .overwrite_output()\n",
        "            .compile()\n",
        "        )\n",
        "    else:\n",
        "        args = (\n",
        "            ffmpeg\n",
        "            .input('pipe:', format='rawvideo', pix_fmt='rgb24', \n",
        "                s='{}x{}'.format(widthOut, heightOut), \n",
        "                framerate=fps_out )\n",
        "            .output(out_filename , pix_fmt='yuv420p', **{'c:v': codec})\n",
        "            .global_args(\"-hide_banner\")\n",
        "            .overwrite_output()\n",
        "            .compile()\n",
        "        )\n",
        "    return subprocess.Popen(args, stdin=subprocess.PIPE)\n",
        "\n",
        "### The model changes the resolution, processes blank to find new resolution\n",
        "def getOutputResolution():\n",
        "    #process a blank frame and return dimesions\n",
        "    blank = np.zeros([height,width,3],dtype=np.uint8)\n",
        "    blank.fill(255)\n",
        "    fastAI_image = Image(pil2tensor(blank, dtype=np.float32).div_(255))\n",
        "    p,img_hr,b = learn.predict(fastAI_image)\n",
        "    im = image2np(img_hr)\n",
        "    x = im.shape\n",
        "    out_height = x[0]\n",
        "    out_width = x[1]\n",
        "    return int(out_width), int(out_height)\n",
        "\n",
        "### This is where all the magic happens\n",
        "def processFrame(frame) :\n",
        "    global INCR\n",
        "    ### Frame comes in as np array\n",
        "    #Load image in fastai's framework as an image\n",
        "    fastAI_image = Image(pil2tensor(frame, dtype=np.float32).div_(255))\n",
        "    # Inference\n",
        "    p,img_hr,b = learn.predict(fastAI_image)\n",
        "    # Convert output tensor into np array\n",
        "    im = image2np(img_hr)\n",
        "    # alpha and beta control line output darkness / warmness\n",
        "    norm_image = cv2.normalize(im, None, alpha=-60, beta=260, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "    INCR += 1\n",
        "    # enabling the next 2 lines will also output images when processing videos\n",
        "    #outCV2 = cv2.cvtColor(norm_image, cv2.COLOR_RGB2BGR )\n",
        "    #cv2.imwrite(output_name+ str(INCR) + \".png\", outCV2)  # INCR is just a frame counter\n",
        "    return norm_image \n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    INCR = 0\n",
        "\n",
        "    learn = modelDeviceLoadSelect()\n",
        "    outWidth, outHeight = getOutputResolution()\n",
        "    estimatedFrames = fps * seconds\n",
        "\n",
        "    print('Model = ', pathToModel)\n",
        "    print('*** Video In***')\n",
        "    print('fps = ', str(fps))\n",
        "    print('width = ', str(width))\n",
        "    print('height = ', str(height))\n",
        "    print('seconds = ', str(seconds))\n",
        "    print('AUDIO = ', AUDIO)\n",
        "    print()\n",
        "    print('*** Video Out***')\n",
        "    print('outWidth = ', str(outWidth))\n",
        "    print('outHeight = ', str(outHeight))\n",
        "    print('output_name = ', output_name)\n",
        "    print()\n",
        "    #progress bar\n",
        "    print('estimatedFrames = ', estimatedFrames)\n",
        "    out = display(progress(0, 100), display_id=True)\n",
        "\n",
        "    inputVid = 'input.mp4'\n",
        "    ffmpegDecode = vid2np(inputVid)\n",
        "    ffmpegEncode = np2vid(output_name, fps, inputVid, outWidth, outHeight)\n",
        "\n",
        "    while True:\n",
        "        timeMark = time.process_time()\n",
        "        in_frame = readFrameAsNp(ffmpegDecode, width, height)\n",
        "        if in_frame is None:\n",
        "            logger.info('End of input stream')\n",
        "            break\n",
        "\n",
        "        logger.debug('Processing frame')\n",
        "        out_frame = processFrame(in_frame)\n",
        "        writeFrameAsByte(ffmpegEncode, out_frame)\n",
        "\n",
        "        #progress bar\n",
        "        out.update(progress(INCR, estimatedFrames))\n",
        "        minutesRemaining = str(round((estimatedFrames-INCR)*(time.process_time()-timeMark)/60))\n",
        "        print(\"\\rEstimated Minutes Remaining = \", minutesRemaining, end=\"\")\n",
        "\n",
        "    logger.info('Waiting for ffmpegDecode')\n",
        "    ffmpegDecode.wait()\n",
        "\n",
        "    logger.info('Waiting for ffmpegEncode')\n",
        "    ffmpegEncode.stdin.close()\n",
        "    ffmpegEncode.wait()\n",
        "\n",
        "    logger.info('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFERENCE DEVICE : cuda\n",
            "Model =  ArtLine_1024.pkl\n",
            "*** Video In***\n",
            "fps =  29.97\n",
            "width =  640\n",
            "height =  360\n",
            "seconds =  206.5\n",
            "AUDIO =  True\n",
            "\n",
            "*** Video Out***\n",
            "outWidth =  1024\n",
            "outHeight =  820\n",
            "output_name =  ocieElliot.likeAriver.artLine_1024.mp4\n",
            "\n",
            "estimatedFrames =  6188.804999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='3471'\n",
              "            max='6188.804999999999',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            3471\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Estimated Minutes Remaining =  17"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBsMMC0h-k-Q"
      },
      "source": [
        "# Download result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFnYWciQ-qMy"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(output_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}