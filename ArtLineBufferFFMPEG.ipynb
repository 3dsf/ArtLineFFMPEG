{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArtLineFFMPEG.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Y8AgUL1FgGEq",
        "yb_SIOJ7QO30",
        "THlQJklGgs3z",
        "0PDg63ZR3iKV",
        "Yt5OjMJxEcmz",
        "s5nvx843QCdL",
        "bap7Mn7v8XvY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3dsf/ArtLineFFMPEG/blob/main/ArtLineBufferFFMPEG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8AgUL1FgGEq"
      },
      "source": [
        "# In Construction\n",
        "\n",
        "# ArtLine Video Conversion\n",
        "implementation of \n",
        "https://github.com/vijishmadhavan/ArtLine\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek-yZXyUqvQd"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRjmZ9FD4mAg"
      },
      "source": [
        "## Install Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8YPFvvMVVvx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed08caf8-f219-4145-c34b-b0ae28b0fc25"
      },
      "source": [
        "!apt install ffmpeg\n",
        "!pip install youtube-dl fastai==1.0.61 ffmpeg-python"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "Requirement already satisfied: youtube-dl in /usr/local/lib/python3.6/dist-packages (2021.1.3)\n",
            "Requirement already satisfied: fastai==1.0.61 in /usr/local/lib/python3.6/dist-packages (1.0.61)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (4.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (1.4.1)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (1.3.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (0.8.1+cu101)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (0.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (1.1.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (2.23.0)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (7.352.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (20.8)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (1.19.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (7.0.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (1.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (2.7.1)\n",
            "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61) (2.2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==1.0.61) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==1.0.61) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.61) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.61) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.61) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.61) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai==1.0.61) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai==1.0.61) (3.7.4.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.61) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.61) (0.10.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (51.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->fastai==1.0.61) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THlQJklGgs3z"
      },
      "source": [
        "# ---> Select your video to process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WulJZB8GWWgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803cb85c-9b35-4ce4-c3fa-f4d6f3e6dcef"
      },
      "source": [
        "youtubeVideo = \"https://www.youtube.com/watch?v=bSvEwnYI2Lc\" #@param {type:\"string\"}\n",
        "!rm input.mp4\n",
        "!time(youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio' --merge-output-format mp4 --output \"input.%(ext)s\"  $youtubeVideo)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'input.mp4': No such file or directory\n",
            "[youtube] bSvEwnYI2Lc: Downloading webpage\n",
            "[youtube] bSvEwnYI2Lc: Downloading MPD manifest\n",
            "[dashsegments] Total fragments: 28\n",
            "[download] Destination: input.f137.mp4\n",
            "\u001b[K[download] 100% of 69.18MiB in 00:23\n",
            "[dashsegments] Total fragments: 15\n",
            "[download] Destination: input.f140.m4a\n",
            "\u001b[K[download] 100% of 2.07MiB in 00:03\n",
            "[ffmpeg] Merging formats into \"input.mp4\"\n",
            "Deleting original file input.f137.mp4 (pass -k to keep)\n",
            "Deleting original file input.f140.m4a (pass -k to keep)\n",
            "\n",
            "real\t0m30.028s\n",
            "user\t0m1.314s\n",
            "sys\t0m0.494s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt5OjMJxEcmz"
      },
      "source": [
        "# ---> Select the Model to Use\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOGWZjslqwGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d27563-48c8-41bf-c885-f0a10fe34f44"
      },
      "source": [
        "import os.path as path\n",
        "import subprocess\n",
        "\n",
        "artLineModel = \"ArtLine_1024.pkl\" #@param [\"ArtLine_500.pkl\", \"ArtLine_650.pkl\", \"ArtLine_1024.pkl\"]\n",
        "pathToModel = path.join(\"/content/drive/\",artLineModel)\n",
        "\n",
        "downloadModel = {\n",
        "    \"ArtLine_500.pkl\": \"https://www.dropbox.com/s/p9lynpwygjmeed2/ArtLine_500.pkl\",\n",
        "    \"ArtLine_650.pkl\": \"https://www.dropbox.com/s/starqc9qd2e1lg1/ArtLine_650.pkl\",\n",
        "    \"ArtLine_1024.pkl\": \"https://www.dropbox.com/s/rq90q9lr9arwdp8/ArtLine_1024%20%281%29.pkl\"\n",
        "}\n",
        "if path.isfile(pathToModel) == False : \n",
        "    if path.isfile(artLineModel) == False :\n",
        "        import subprocess\n",
        "        print(\"Downloading\")\n",
        "        subprocess.call(\"wget -O \" + artLineModel + \" \" + downloadModel[artLineModel] , shell=True)\n",
        "        pathToModel = artLineModel\n",
        "    else :\n",
        "        print(\"Found Local Version\")\n",
        "        pathToModel = artLineModel"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bap7Mn7v8XvY"
      },
      "source": [
        "# ---> Select the Output Name and **Encode**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcuaaaJYW3ip"
      },
      "source": [
        "output_name = \"nomke.heycat.mp4\" #@param {type:\"string\"}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5nvx843QCdL"
      },
      "source": [
        "# Run Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHX3_NWZNies",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "f7c7a8b6-59b0-4c82-943e-3f31263ace6e"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import subprocess\n",
        "import glob\n",
        "import argparse\n",
        "import time\n",
        "import logging as logger\n",
        "\n",
        "import torchvision.transforms as T\n",
        "import fastai\n",
        "#from fastai.vision import *\n",
        "from fastai.utils.mem import *\n",
        "from fastai.vision import open_image, load_learner, image, torch\n",
        "\n",
        "import ffmpeg\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "#There is scaling warning that might come up, and this block supresses user warnings\n",
        "#Comment out this block if your don't mind seeing the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
        "\n",
        "MODEL_FILE_NAME = pathToModel\n",
        "\n",
        "\n",
        "#------   this class is from the original project and is the main functional part\n",
        "\n",
        "class FeatureLoss(nn.Module):\n",
        "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
        "        super().__init__()\n",
        "        self.m_feat = m_feat\n",
        "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
        "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
        "        self.wgts = layer_wgts\n",
        "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
        "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
        "\n",
        "    def make_features(self, x, clone=False):\n",
        "        self.m_feat(x)\n",
        "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        out_feat = self.make_features(target, clone=True)\n",
        "        in_feat = self.make_features(input)\n",
        "        self.feat_losses = [base_loss(input,target)]\n",
        "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
        "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
        "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
        "        return sum(self.feat_losses)\n",
        "\n",
        "    def __del__(self): self.hooks.remove()\n",
        "\n",
        "#------   these function are done by me   **NOTICE** they contain the default model info\n",
        "\n",
        "def setupDirs(dir_list):\n",
        "    for sDir in dir_list :\n",
        "        os.makedirs(sDir, exist_ok=True)\n",
        "\n",
        "def modelDeviceLoadSelect():  # DETERMINE IF CUDA AVAILABLE and LOAD MODEL\n",
        "    path_script = \".\"  #path_script = os.path.dirname(os.path.abspath(__file__))\n",
        "    global COMPUTEdEVICE\n",
        "    class Spam(int): pass\n",
        "    try: \n",
        "        COMPUTEdEVICE = Spam(COMPUTEdEVICE)\n",
        "    except:\n",
        "        print()\n",
        "    print (COMPUTEdEVICE, isinstance(COMPUTEdEVICE, int))\n",
        "    if torch.cuda.is_available() and isinstance(COMPUTEdEVICE, int):\n",
        "        def load_model():\n",
        "            global USEgPU\n",
        "            learn = load_learner(path_script, MODEL_FILE_NAME, device=COMPUTEdEVICE )\n",
        "            USEgPU = True\n",
        "            print(\"INFERENCE DEVICE : cuda\")\n",
        "            return learn\n",
        "    else:\n",
        "        def load_model():\n",
        "            learn = load_learner(path_script, MODEL_FILE_NAME, device='cpu')\n",
        "            print(\"INFERENCE DEVICE : cpu\")\n",
        "            return learn\n",
        "    learn=load_model()\n",
        "    return learn\n",
        "\n",
        "def processFolder(input_folder, output_folder) :\n",
        "    input_imgs = glob.glob(os.path.join(input_folder, \"*\"))\n",
        "    count_imgs = len(input_imgs)\n",
        "    if count_imgs == 0 :\n",
        "        print(\"  No Images Found  in \\\"\", input_folder, \"\\\" folder\")\n",
        "        quit()\n",
        "    for i, img in enumerate(input_imgs):\n",
        "        timeMark = time.process_time()\n",
        "        # Load image in fastai's framework\n",
        "        p,img_hr,b = learn.predict(open_image(img))\n",
        "        # Convert output tensor into np array\n",
        "        im = image2np(img_hr)\n",
        "        # alpha and beta control line output darkness \n",
        "        norm_image = cv2.normalize(im, None, alpha=-60, beta=260, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "        # Save file\n",
        "        cv2.imwrite('output/' + os.path.basename(img), norm_image)\n",
        "        print(\"{} ({}/{})\".format(img, i+1 , count_imgs) + \" time : \" + str(time.process_time()-timeMark))\n",
        "    return \n",
        "\n",
        "#--------- this block of functions is mostly python-ffmpeg\n",
        "\n",
        "# This is the function for processing VIDEO frames\n",
        "def processFrame(frame) :\n",
        "    global INCR, WIDTHoUT, HEIGHToUT\n",
        "    ### Frame comes in as np array\n",
        "    # jenky np array to buffer, because of poor cv2 support in fastai=1, or my poor skills\n",
        "    is_success, buffer = cv2.imencode(\".bmp\", frame)  \n",
        "    io_buf = io.BytesIO(buffer)\n",
        "    # Load image in fastai's framework\n",
        "    p,img_hr,b = learn.predict(open_image(io_buf))\n",
        "    # Convert output tensor into np array\n",
        "    im = image2np(img_hr)\n",
        "    # alpha and beta control line output darkness \n",
        "    norm_image = cv2.normalize(im, None, alpha=-60, beta=260, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U) #16S)\n",
        "    INCR += 1\n",
        "    # enabling this line will also output images when processing videos\n",
        "    #cv2.imwrite('output/' + str(INCR) + \".png\", norm_image)  # INCR is just a frame counter\n",
        "    return norm_image \n",
        "\n",
        "def getVideoMetaData(filename):\n",
        "    logger.info('Getting video size for {!r}'.format(filename))\n",
        "    probe = ffmpeg.probe(filename)\n",
        "    video_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')\n",
        "    print(video_info)  #see what available\n",
        "    width = int(video_info['width'])\n",
        "    height = int(video_info['height'])\n",
        "    fps = video_info['r_frame_rate']\n",
        "    try:\n",
        "        bits_in = video_info['bits_per_raw_sample']  # h264_cuvid complains with 10 bit\n",
        "    except:\n",
        "        bits_in = 10\n",
        "    print (bits_in)\n",
        "    time.sleep(5)\n",
        "    #total_frames = int(video_info['nb_frames'])\n",
        "    return width, height, fps, bits_in\n",
        "\n",
        "def checkForAudio(in_filename):\n",
        "    streams = ffmpeg.probe(in_filename)[\"streams\"]\n",
        "    for stream in streams:\n",
        "        if stream[\"codec_type\"] == \"audio\":\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def readFrameAsNp(ffmpegDecode, width, height):\n",
        "    logger.debug('Reading frame')\n",
        "\n",
        "    # Note: RGB24 == 3 bytes per pixel.\n",
        "    frame_size = width * height * 3\n",
        "    in_bytes = ffmpegDecode.stdout.read(frame_size)\n",
        "    if len(in_bytes) == 0:\n",
        "        frame = None\n",
        "    else:\n",
        "        assert len(in_bytes) == frame_size\n",
        "        frame = (\n",
        "            np\n",
        "            .frombuffer(in_bytes, np.uint8)\n",
        "            .reshape([height, width, 3])\n",
        "        )\n",
        "    return frame\n",
        "\n",
        "def writeFrameAsByte(ffmpegEncode, frame):\n",
        "    logger.debug('Writing frame')\n",
        "    ffmpegEncode.stdin.write(\n",
        "        frame\n",
        "        .astype(np.uint8)\n",
        "        .tobytes()\n",
        "    )\n",
        "\n",
        "def aFrame():\n",
        "    global WIDTHoUT\n",
        "    global HEIGHToUT\n",
        "    width, height, z, zz = getVideoMetaData(input_path)\n",
        "    img = np.zeros([height,width,3],dtype=np.uint8)\n",
        "    img.fill(255)\n",
        "    is_success, buffer = cv2.imencode(\".bmp\", img)\n",
        "    io_buf = io.BytesIO(buffer)\n",
        "    # Load image in fastai's framework\n",
        "    p,img_hr,b = learn.predict(open_image(io_buf))\n",
        "    # Convert output tensor into np array\n",
        "    im = image2np(img_hr)\n",
        "    x = im.shape\n",
        "    WIDTHoUT = x[1]\n",
        "    HEIGHToUT = x[0]\n",
        "    print(WIDTHoUT, HEIGHToUT)\n",
        "\n",
        "def vid2np(in_filename, bits_in):\n",
        "    logger.info('vid2np() -- Decoding to pipe')\n",
        "    #print(int(bits_in), USEgPU)\n",
        "    if int(bits_in) == 8 and USEgPU :\n",
        "        args = (\n",
        "            ffmpeg\n",
        "            .input(in_filename,\n",
        "                hwaccel_device=COMPUTEdEVICE,\n",
        "                hwaccel='cuvid', **{'c:v': 'h264_cuvid'}, \n",
        "                hwaccel_output_format='rawvideo')\n",
        "            .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
        "            .global_args(\"-hide_banner\")\n",
        "            .compile()\n",
        "        )\n",
        "    else:\n",
        "        args = (\n",
        "            ffmpeg\n",
        "            .input(in_filename,\n",
        "                **{'c:v': 'h264'})\n",
        "            .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
        "            .global_args(\"-hide_banner\")\n",
        "            .compile()\n",
        "        )\n",
        "    return subprocess.Popen(args, stdout=subprocess.PIPE)\n",
        "\n",
        "def np2vid(out_filename, fps_out, in_file):\n",
        "    logger.info('np2vid() encoding from pipe')\n",
        "    codec = 'h264_nvenc' if USEgPU else 'h264'\n",
        "    if checkForAudio(in_file) :\n",
        "        pipeline2 = ffmpeg.input(in_file)\n",
        "        audio = pipeline2.audio\n",
        "        args = (\n",
        "            ffmpeg\n",
        "            .input('pipe:', format='rawvideo', pix_fmt='rgb24',\n",
        "                s='{}x{}'.format(WIDTHoUT, HEIGHToUT),\n",
        "                framerate=fps_out )\n",
        "            .output(audio, out_filename , pix_fmt='yuv420p', **{'c:v': codec}, \n",
        "                shortest=None, acodec='copy')\n",
        "            .global_args(\"-hide_banner\")\n",
        "            .overwrite_output()\n",
        "            .compile()\n",
        "        )\n",
        "    else:\n",
        "        args = (\n",
        "            ffmpeg\n",
        "            .input('pipe:', format='rawvideo', pix_fmt='rgb24', \n",
        "                s='{}x{}'.format(WIDTHoUT, HEIGHToUT), \n",
        "                framerate=fps_out )\n",
        "            .output(audio, out_filename , pix_fmt='yuv420p', **{'c:v': codec})\n",
        "            .global_args(\"-hide_banner\")\n",
        "            .overwrite_output()\n",
        "            .compile()\n",
        "        )\n",
        "    return subprocess.Popen(args, stdin=subprocess.PIPE)\n",
        "\n",
        "def run(in_file, out_file, process_frame, width_out=0, height_out=0):\n",
        "    width, height, fps_out, bits_in = getVideoMetaData(in_file)\n",
        "    ffmpegDecode = vid2np(in_file, bits_in)\n",
        "    ffmpegEncode = np2vid(out_file, fps_out, in_file)\n",
        "    while True:\n",
        "        in_frame = readFrameAsNp(ffmpegDecode, width, height)\n",
        "        if in_frame is None:\n",
        "            logger.info('End of input stream')\n",
        "            break\n",
        "\n",
        "        logger.debug('Processing frame')\n",
        "        out_frame = processFrame(in_frame)\n",
        "        writeFrameAsByte(ffmpegEncode, out_frame)\n",
        "\n",
        "    logger.info('Waiting for ffmpegDecode')\n",
        "    ffmpegDecode.wait()\n",
        "\n",
        "    logger.info('Waiting for ffmpegEncode')\n",
        "    ffmpegEncode.stdin.close()\n",
        "    ffmpegEncode.wait()\n",
        "\n",
        "    logger.info('Done')\n",
        "\n",
        "\n",
        "### -----------   \n",
        "\n",
        "#def input_parser() :\n",
        "#    parser = argparse.ArgumentParser(description=__doc__)\n",
        "#    parser.add_argument('-i', action=\"store\", dest=\"source_input\", default=\"input\",\n",
        "#            help=\"This can be either a movie file or a folder -- default= input (folder)\")\n",
        "#    parser.add_argument('-o', action=\"store\", dest=\"source_output\", default=\"output\",\n",
        "#            help=\"Should be of same type as input: movie->movie or img->img -- default= output (folder)\")\n",
        "#    # selects GPU by ID (int), or CPU by any non-int\n",
        "#    parser.add_argument('-c', action=\"store\", dest=\"compute_device\", default=0,\n",
        "#            help=\"Input your prefered GPU by ID (int) or type \\'cpu\\' for cpu inference\")\n",
        "#    results = parser.parse_args()\n",
        "#    return results \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    INCR = 0 \n",
        "    WIDTHoUT = 1024  # will change to output\n",
        "    HEIGHToUT = 820 # will change to output\n",
        "    USEgPU = False  # Turns on in modelDeviceLoadSelect()\n",
        "\n",
        "    setupDirs([\"input\",\"output\"])\n",
        "\n",
        "    #iParser = input_parser()\n",
        "    #checkModelExists(MODEL_FILE_NAME)\n",
        "    COMPUTEdEVICE = 0 #COMPUTEdEVICE = iParser.compute_device\n",
        "    learn = modelDeviceLoadSelect()\n",
        "\n",
        "    input_path = \"input.mp4\" #input_path = iParser.source_input\n",
        "    output_path = output_name #output_path = iParser.source_output\n",
        "    if os.path.isdir(input_path):\n",
        "        print(\"INPUT DIRECTORY : \", input_path, \"\\n\")\n",
        "        processFolder(input_path, output_path)\n",
        "    elif os.path.isfile(input_path):\n",
        "        #run 1 frame\n",
        "        aFrame()\n",
        "        print(\"INPUT FILE : \", input_path)\n",
        "        if os.path.isdir(output_path):\n",
        "            output_path = os.path.join(output_path, \"out.ArtLine.\" \n",
        "                    + time.strftime(\"%YY%m%d-%H.%M.%S\") + \".mp4\")\n",
        "        run(input_path, output_path, processFrame)\n",
        "    else:\n",
        "        print(\"DIRECTORY / FILE NOT FOUND : \", input_path)\n",
        "    print()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 True\n",
            "INFERENCE DEVICE : cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5b057df20953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;31m#run 1 frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0maFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INPUT FILE : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-5b057df20953>\u001b[0m in \u001b[0;36maFrame\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mWIDTHoUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mHEIGHToUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetVideoMetaData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-5b057df20953>\u001b[0m in \u001b[0;36mgetVideoMetaData\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetVideoMetaData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Getting video size for {!r}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mprobe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffmpeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0mvideo_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprobe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'streams'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'codec_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'video'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_info\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#see what available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'ffmpeg' has no attribute 'probe'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBsMMC0h-k-Q"
      },
      "source": [
        "# Download result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFnYWciQ-qMy"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(output_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}